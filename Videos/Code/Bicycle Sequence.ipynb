{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Input, \\\n",
    "    InputLayer,Conv2D,MaxPool2D,UpSampling2D,Conv2DTranspose,Cropping2D,add,average\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape=(480,320,3)\n",
    "# The encoder 1\n",
    "encoder1_1 = Input(img_shape,name='encoder1_input')\n",
    "encoder1_2 = Conv2D(filters=32,kernel_size=3,strides=2,padding='same',name='E1Layer1')(encoder1_1)\n",
    "encoder1_3 = Conv2D(filters=32,kernel_size=3,strides=2,padding='same',name='E1Layer2')(encoder1_2)\n",
    "encoder1_4 = Conv2D(filters=32,kernel_size=3,strides=2,padding='same',name='E1Layer3')(encoder1_3)\n",
    "# encoder1_5 = Conv2D(filters=32,kernel_size=3,strides=2,padding='same',name='E1Layer4')(encoder1_4)\n",
    "\n",
    "encoder1 = Model(encoder1_1,encoder1_4)\n",
    "\n",
    "# The decoder 1\n",
    "decoder1_1 = Input(encoder1.get_layer('E1Layer3').output_shape[1:],name='decoder1_input')\n",
    "# decoder1_2 = Conv2DTranspose(filters=32,kernel_size=3,strides=2,padding='same',name='D1Layer1')(decoder1_1)\n",
    "decoder1_3 = Conv2DTranspose(filters=32,kernel_size=3,strides=2,padding='same',name='D1Layer2')(decoder1_1)\n",
    "decoder1_4 = Conv2DTranspose(filters=32,kernel_size=3,strides=2,padding='same',name='D1Layer3')(decoder1_3)\n",
    "decoder1_5 = Conv2DTranspose(filters=3,kernel_size=3,strides=2,padding='same',name='D1Layer4')(decoder1_4)\n",
    "\n",
    "decoder1 = Model(decoder1_1,decoder1_5)\n",
    "\n",
    "inp = Input(img_shape)\n",
    "code = encoder1(inp)\n",
    "reconstruction = decoder1(code)\n",
    "autoencoder1 = Model(inp,reconstruction)\n",
    "\n",
    "##################################\n",
    "####### Second Autoencoder #######\n",
    "##################################\n",
    "\n",
    "# The encoder 2\n",
    "encoder2_1 = Input(img_shape,name='encoder2_input')\n",
    "encoder2_2 = Conv2D(filters=256,kernel_size=3,strides=2,padding='same',activation='relu',activity_regularizer=l1(10e-10),name='E2Layer1')(encoder2_1)\n",
    "encoder2_3 = Conv2D(filters=128,kernel_size=3,strides=2,padding='same',activation='relu',activity_regularizer=l1(10e-10),name='E2Layer2')(encoder2_2)\n",
    "encoder2_4 = Conv2D(filters=64,kernel_size=3,strides=2,padding='same',activation='relu',activity_regularizer=l1(10e-10),name='E2Layer3')(encoder2_3)\n",
    "# encoder2_5 = Conv2D(filters=32,kernel_size=3,strides=2,padding='same',activation='relu',activity_regularizer=l1(10e-10),name='E2Layer4')(encoder2_4)\n",
    "\n",
    "# The decoder 2\n",
    "decoder2_2 = Conv2DTranspose(filters=128,kernel_size=3,strides=2,padding='same',activation='relu',activity_regularizer=l1(10e-10),name='D2Layer1')(encoder2_4)\n",
    "add2_1 = average([decoder2_2,encoder2_3]) # Residual Connection \n",
    "# decoder2_3 = Conv2DTranspose(filters=128,kernel_size=3,strides=2,padding='same',activation='relu',activity_regularizer=l1(10e-10),name='D2Layer2')(add2_1)\n",
    "decoder2_4 = Conv2DTranspose(filters=256,kernel_size=3,strides=2,padding='same',activation='relu',activity_regularizer=l1(10e-10),name='D2Layer3')(add2_1)\n",
    "add2_2 = average([decoder2_4,encoder2_2]) # Residual Connection \n",
    "decoder2_5 = Conv2DTranspose(filters=3,kernel_size=3,strides=2,padding='same',activation='relu',activity_regularizer=l1(10e-10),name='D2Layer4')(add2_2)\n",
    "\n",
    "autoencoder2 = Model(encoder2_1,decoder2_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_52\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder2_input (InputLayer)     [(None, 480, 320, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "E2Layer1 (Conv2D)               (None, 240, 160, 256 7168        encoder2_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "E2Layer2 (Conv2D)               (None, 120, 80, 128) 295040      E2Layer1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "E2Layer3 (Conv2D)               (None, 60, 40, 64)   73792       E2Layer2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "D2Layer1 (Conv2DTranspose)      (None, 120, 80, 128) 73856       E2Layer3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average (Average)               (None, 120, 80, 128) 0           D2Layer1[0][0]                   \n",
      "                                                                 E2Layer2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "D2Layer3 (Conv2DTranspose)      (None, 240, 160, 256 295168      average[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 240, 160, 256 0           D2Layer3[0][0]                   \n",
      "                                                                 E2Layer1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "D2Layer4 (Conv2DTranspose)      (None, 480, 320, 3)  6915        average_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 751,939\n",
      "Trainable params: 751,939\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(480*320*3)/(60*40*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "DATASET = r'C:\\Users\\saad\\Desktop\\Autoencoders\\Videos\\Dataset'  # where there is dataset\n",
    "DATASET_NAME = ['bunny_video.mp4','Rabbit_video.mp4','bicycle_sequence.mp4'] # Name of the video\n",
    "# where you want to save the frames\n",
    "FRAMES = r'C:\\Users\\saad\\Desktop\\Autoencoders\\Videos\\Results'\n",
    "FRAME_NAME = ['bunny','rabbit','bicycle']\n",
    "FRAME_TRAIN =['bunny_train','rabbit_train','bicycle_train']\n",
    "FRAME_TEST = ['bunny_test','rabbit_test','bicycle_test']\n",
    "names = [0 , 0 , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the video frames for each video\n",
    "for idx,f in enumerate(FRAME_NAME):\n",
    "    names[idx],fps,width,height = read_video(os.path.join(FRAMES,f),os.path.join(DATASET,DATASET_NAME[idx]))\n",
    "    print(f'{f} completed')\n",
    "\n",
    "#Randomly selecting certain number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is for bunny\n",
    "# 1 is for rabbit\n",
    "# 2 is for bicycle\n",
    "\n",
    "from shutil import copy\n",
    "\n",
    "for i in tqdm(range(len(names)),desc='categorization'):\n",
    "    \n",
    "    train,test = splitter(np.array(names[i]),0.2)\n",
    "    \n",
    "    for j in tqdm(range(len(train)),desc='Training Data'):\n",
    "        copy(os.path.join(FRAMES,FRAME_NAME[i],train[j]),os.path.join(FRAMES,FRAME_TRAIN[i]))\n",
    "        \n",
    "    for k in tqdm(range(len(test)),desc='Testing Data'):\n",
    "        copy(os.path.join(FRAMES,FRAME_NAME[i],test[k]),os.path.join(FRAMES,FRAME_TEST[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =[]\n",
    "test = []\n",
    "\n",
    "for j in tqdm(range(len(train)),desc='Training Data'):\n",
    "    copy(os.path.join(FRAMES,FRAME_NAME[i],train[j]),os.path.join(FRAMES,FRAME_TRAIN[i]))\n",
    "        \n",
    "    for k in tqdm(range(len(test)),desc='Testing Data'):\n",
    "        copy(os.path.join(FRAMES,FRAME_NAME[i],test[k]),os.path.join(FRAMES,FRAME_TEST[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(FRAMES,FRAME_NAME[0],FRAME_TRAIN[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for n in tqdm(FRAME_TRAIN):\n",
    "    foo = os.path.join(FRAMES,n)\n",
    "    im = np.array(read_imgs(foo,os.listdir(foo),2,640,480))\n",
    "    images.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = []\n",
    "for n in tqdm(FRAME_TEST):\n",
    "    foo = os.path.join(FRAMES,n)\n",
    "    im = np.array(read_imgs(foo,os.listdir(foo),2,640,480))\n",
    "    images_test.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images1 = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images1[0].shape,images1[1].shape,images1[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images2= images2.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in images for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array(flat_list)\n",
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test1 = [item for sublist in images_test for item in sublist]\n",
    "image_test2 = np.array(image_test1)\n",
    "image_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1,model2 = build_autoencoder(f.shape[1:],512,'Hi-Res',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='mse',optimizer='adam',metrics=['mae'])\n",
    "model2.compile(loss='mse',optimizer='adam',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = r'C:\\Users\\saad\\Desktop\\Autoencoders\\Videos\\Results\\Weights'\n",
    "model1 = model_fit(model1,'model1_combined',WEIGHTS,f,f,200,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_intermediate = data_prep(f,model1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = model_fit(model2,'model2_combined',WEIGHTS,train_intermediate,f,200,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = data_prep(image_test2,model1,model2)\n",
    "# predictions = predictions * 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ids = 299\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(image_test2[ids,:,:,:])\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(132)\n",
    "x = model1.predict(np.expand_dims(image_test2[ids],axis=0))\n",
    "x = x.reshape(480,320,3)\n",
    "plt.imshow(x.astype(int))\n",
    "plt.title('Model1 Output')\n",
    "\n",
    "plt.subplot(133)\n",
    "y = predictions2[ids]\n",
    "plt.imshow(y.astype(int))\n",
    "plt.title('Final Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test2[:1,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = model1.predict(np.expand_dims(f[0],axis=0))\n",
    "g=g.reshape(480,320,3)\n",
    "plt.imshow(g.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1.load_weights(os.path.join(WEIGHTS,'model1_combined.hdf5'))\n",
    "model2.load_weights(os.path.join(WEIGHTS,'model2_combined.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(FRAMES,FRAME_NAME[1]))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(read_imgs(os.getcwd(),os.listdir(os.getcwd()),2,640,480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_new1 = data_prep(images,model1,model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_creater('Recon_rabbit_new1.avi',os.getcwd(),25.,640,480,predictions_new1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\saad\\Desktop\\Autoencoders\\Videos\\Dataset'\n",
    "vid_name = 'Bicycle_Sequence.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names,fps,width,height=read_video(os.getcwd(),os.path.join(path,vid_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The fps is {fps}, The width of the frame is {width} and the height of the frame is {height}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(read_imgs(os.getcwd(),names,2,640,480))\n",
    "images = images.astype('float32')/255.\n",
    "print(f'The shape of the images is {images.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = images.shape[1:]\n",
    "print(img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1,model2 = build_autoencoder(img_shape,512,'Hi-Res',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = r'C:\\Users\\saad\\Desktop\\Autoencoders\\Videos\\Results\\Weights'\n",
    "weights = weights.replace('\\\\','/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.load_weights(os.path.join(weights,'model1.hdf5'))\n",
    "model2.load_weights(os.path.join(weights,'model2.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_new = model1.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img_new[75,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "preds=[]\n",
    "for i in tqdm(range(len(img_new))):\n",
    "    preds.append(model2.predict(np.expand_dims(img_new[i],axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = np.array(preds)\n",
    "pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr= pr.reshape(224,480,320,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pr[75,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[75,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = 3\n",
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(images[im,:,:,:])\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(img_new[im,:,:,:])\n",
    "plt.title('Intermediate')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(pr[im,:,:,:])\n",
    "plt.title('Reconstructed')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pr * 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO = r'C:\\Users\\saad\\Desktop\\Autoencoders\\Videos\\Results\\Video'\n",
    "video_creater('Recon_bicycle1.avi',VIDEO,25.,640,480,predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " original_video('Original_bicycle.avi',VIDEO,os.getcwd(),25.,names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=['a','b','c']\n",
    "\n",
    "for i,j in enumerate(lst):\n",
    "    print('i:',i)\n",
    "    print('j:',j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
