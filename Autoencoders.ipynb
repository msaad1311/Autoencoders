{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(28 * 28 * num_images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(num_images, 28,28)\n",
    "        return data\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = extract_data('train-images-idx3-ubyte.gz', 60000)\n",
    "test_data = extract_data('t10k-images-idx3-ubyte.gz', 10000)\n",
    "\n",
    "train_labels = extract_labels('train-labels-idx1-ubyte.gz',60000)\n",
    "test_labels = extract_labels('t10k-labels-idx1-ubyte.gz',10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (images) shape: (60000, 28, 28)\n",
      "Test set (images) shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Shapes of training set\n",
    "print(\"Training set (images) shape: {shape}\".format(shape=train_data.shape))\n",
    "\n",
    "# Shapes of test set\n",
    "print(\"Test set (images) shape: {shape}\".format(shape=test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f8adefb088>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(121)\n",
    "curr_img = np.reshape(train_data[0], (28,28))\n",
    "curr_lbl = train_labels[0]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(test_data[0], (28,28))\n",
    "curr_lbl = train_labels[0]\n",
    "plt.imshow(curr_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.reshape(-1, 28,28, 1)\n",
    "test_data = test_data.reshape(-1, 28,28, 1)\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data / np.max(train_data)\n",
    "test_data = test_data / np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,\n",
    "                                                             train_data, \n",
    "                                                             test_size=0.2, \n",
    "                                                             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic Parameters\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "inChannel = 1\n",
    "x, y = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(input_img):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "\n",
    "    #decoder\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 128\n",
    "    up1 = UpSampling2D((2,2))(conv4) # 14 x 14 x 128\n",
    "    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 64\n",
    "    up2 = UpSampling2D((2,2))(conv5) # 28 x 28 x 64\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape = (x, y, inChannel))\n",
    "autoencoder = Model(input_img, autoencoder(input_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(loss='mse', optimizer = 'adam',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node functional_1/conv2d/Conv2D (defined at <ipython-input-14-6f2711857f3e>:3) ]] [Op:__inference_train_function_1029]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-6f2711857f3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m history = autoencoder.fit(train_X, train_ground, \n\u001b[0;32m      2\u001b[0m                                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                                     validation_data=(valid_X, valid_ground))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node functional_1/conv2d/Conv2D (defined at <ipython-input-14-6f2711857f3e>:3) ]] [Op:__inference_train_function_1029]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(train_X, train_ground, \n",
    "                                    batch_size=batch_size,epochs=epochs,verbose=1,\n",
    "                                    validation_data=(valid_X, valid_ground))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
